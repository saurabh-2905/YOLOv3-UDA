{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import cv2\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#import colormap as cmap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def visualize(index, masks, bounding_boxes):\n",
    "    image = coco.loadImgs(coco.getImgIds()[index])[0]    \n",
    "    anno_ids = coco.getAnnIds(imgIds=[image[\"id\"]])\n",
    "    annos = coco.loadAnns(anno_ids) \n",
    "    \n",
    "    \"\"\"new_annos = []\n",
    "    for single in annos:\n",
    "        single = get_angles(single)\n",
    "        new_annos.append([single])\n",
    "    \n",
    "    annos = new_annos\"\"\"\n",
    "    filename = os.path.join(data_folder,image[\"file_name\"])\n",
    "    img = cv2.imread(str(filename))\n",
    "    print(img.shape)\n",
    "    for anno in annos:\n",
    "        #print(anno)\n",
    "        anno = get_angles(anno)\n",
    "        #c = tuple([int(x) for x in anno[\"category_id\"]])         \n",
    "        if masks:\n",
    "            points = np.array(anno[\"segmentation\"], dtype=np.int32).reshape(1,-1,2)\n",
    "            img = cv2.polylines(img, points, True, 3)\n",
    "        \n",
    "        if bounding_boxes:  \n",
    "                x,y,w,h,a = np.array(anno[\"bbox\"]).astype(np.int32)\n",
    "                #img = cv2.rectangle(img, (x,y),(x + w,y + h),(0,255,255), 3) \n",
    "                img = draw_xywha(img,x,y,w,h,a)\n",
    "                cat = coco.cats[anno['category_id']]['name']\n",
    "                cv2.putText(img, cat, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX ,  0.8, 1, cv2.LINE_AA)            \n",
    "                \n",
    "    \n",
    "    plt.imshow(img[...,::-1])\n",
    "    plt.axis(\"off\")\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def get_angles(ann):\n",
    "    \n",
    "    #print(ann['bbox'])\n",
    "    img_id = ann['image_id']\n",
    "    new_ann = None\n",
    "    # get width and height\n",
    "    if not 'rbbox' in ann:\n",
    "        # using COCO dataset. 4 = [x1,y1,w,h]\n",
    "        coco = True\n",
    "        # convert COCO format: x1,y1,w,h to x,y,w,h\n",
    "        ann['bbox'][0] = ann['bbox'][0] + ann['bbox'][2] / 2\n",
    "        ann['bbox'][1] = ann['bbox'][1] + ann['bbox'][3] / 2\n",
    "        ann['bbox'].append(0)\n",
    "        if ann['bbox'][2] > ann['bbox'][3]:\n",
    "            ann['bbox'][2],ann['bbox'][3] = ann['bbox'][3],ann['bbox'][2]\n",
    "            ann['bbox'][4] -= 90\n",
    "        new_ann = ann['bbox']\n",
    "    else:\n",
    "        # using rotated bounding box datasets. 5 = [cx,cy,w,h,angle]\n",
    "        assert len(ann['rbbox']) == 5, 'Unknown bbox format' # x,y,w,h,a\n",
    "        new_ann = ann['rbbox']\n",
    "        \n",
    "\n",
    "        if new_ann[2] > new_ann[3]:\n",
    "            new_ann[2], new_ann[3] = new_ann[3],new_ann[2]\n",
    "            new_ann[4] -= 90 if new_ann[4] > 0 else -90\n",
    "\n",
    "    if new_ann[2] == new_ann[3]:\n",
    "        new_ann[3] += 1 # force that w < h\n",
    "        \n",
    "    new_ann[4] = np.clip(new_ann[4], -90.0, 90.0 - 1e-14)\n",
    "\n",
    "    assert new_ann[2] < new_ann[3]\n",
    "    assert new_ann[4] >= -90 and new_ann[4] < 90\n",
    "\n",
    "    # override original bounding box with rotated bounding box\n",
    "    ann['bbox'] = torch.Tensor(new_ann)\n",
    "    #print(ann['bbox'])\n",
    "    return ann\n",
    "\n",
    "    \n",
    "def draw_xywha(im, x, y, w, h, angle, color=(255,0,0), linewidth=5):\n",
    "    '''\n",
    "    im: image numpy array, shape(h,w,3), RGB\n",
    "    angle: degree\n",
    "    '''\n",
    "    c, s = np.cos(angle/180*np.pi), np.sin(angle/180*np.pi)\n",
    "    R = np.asarray([[c, s], [-s, c]])\n",
    "    pts = np.asarray([[-w/2, -h/2], [w/2, -h/2], [w/2, h/2], [-w/2, h/2]])\n",
    "    rot_pts = []\n",
    "    for pt in pts:\n",
    "        rot_pts.append(([x, y] + pt @ R).astype(int))\n",
    "    contours = np.array([rot_pts[0], rot_pts[1], rot_pts[2], rot_pts[3]])\n",
    "    cv2.polylines(im, [contours], isClosed=True, color=color,\n",
    "                thickness=linewidth, lineType=cv2.LINE_4)\n",
    "    return im\n",
    "    \n",
    "    \n",
    "#data_folder = \"/localdata/saurabh/dataset/FES/JPEGImages/\"\n",
    "#coco = COCO(\"/localdata/saurabh/dataset/FES/coco/annotations/instances_default_with_rbbox.json\")\n",
    "data_folder = \"/localdata/saurabh/dataset/omnidetector-Flat_(Record_01)/JPEGImages/\"\n",
    "coco = COCO(\"/localdata/saurabh/dataset/omnidetector-Flat_(Record_01)/coco/annotations/instances_training.json\")\n",
    "plt.figure(figsize=(100,100))\n",
    "total = len(coco.getImgIds()) - 1\n",
    "\n",
    "interact(visualize, index=widgets.IntSlider(min=0, max=total, step=1, continuous_update=False), masks=False, bounding_boxes=True);  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "###Input####\n",
    "mode_in = ''\n",
    "dataset = ''\n",
    "image_paths = glob.glob(f\"/localdata/saurabh/yolov3/data/{dataset}/images/{mode_in}/*.jpg\")\n",
    "############\n",
    "\n",
    "\n",
    "image_ids = []\n",
    "image_names = []\n",
    "#print(image_paths[0])\n",
    "##### Edit this part according to the name of the files ####\n",
    "for image in image_paths:\n",
    "    #print(image)\n",
    "    image_name = os.path.splitext(os.path.basename(image))[0]\n",
    "    #print(image_name)\n",
    "    image_names += [image_name]\n",
    "    image_name = image_name.split('_')[0]\n",
    "    image_ids += [image_name]\n",
    "    #break\n",
    "    \n",
    "#print(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anns(img_dir,json_path):\n",
    "        coco = False\n",
    "        print(f'Loading annotations {json_path} into memory...')\n",
    "        with open(json_path, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        for ann in json_data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            #print(img_id)\n",
    "            new_ann = None\n",
    "            # get width and height \n",
    "            if not 'rbbox' in ann:\n",
    "                # using COCO dataset. 4 = [x1,y1,w,h]\n",
    "                coco = True\n",
    "                # convert COCO format: x1,y1,w,h to x,y,w,h\n",
    "                ann['bbox'][0] = ann['bbox'][0] + ann['bbox'][2] / 2\n",
    "                ann['bbox'][1] = ann['bbox'][1] + ann['bbox'][3] / 2\n",
    "                ann['bbox'].append(0)\n",
    "                if ann['bbox'][2] > ann['bbox'][3]:\n",
    "                    ann['bbox'][2], ann['bbox'][3] = ann['bbox'][3], ann['bbox'][2]\n",
    "                    ann['bbox'][4] -= 90\n",
    "                new_ann = ann['bbox']\n",
    "            else:\n",
    "                # using rotated bounding box datasets. 5 = [cx,cy,w,h,angle]\n",
    "                # x,y,w,h,a\n",
    "                assert len(ann['rbbox']) == 5, 'Unknown bbox format'\n",
    "                new_ann = ann['rbbox']\n",
    "\n",
    "                if new_ann[2] > new_ann[3]:\n",
    "                    new_ann[2], new_ann[3] = new_ann[3], new_ann[2]\n",
    "                    new_ann[4] += 90 - np.finfo(np.float32).eps\n",
    "\n",
    "            if new_ann[2] == new_ann[3]:\n",
    "                new_ann[3] += 1  # force that w < h\n",
    "\n",
    "            assert new_ann[2] < new_ann[3]\n",
    "            assert new_ann[4] >= -90 and new_ann[4] < 90\n",
    "\n",
    "            # override original bounding box with rotated bounding box\n",
    "            ann['bbox'] = torch.Tensor(new_ann)\n",
    "            imgid2anns[img_id].append(ann)\n",
    "\n",
    "        for img in json_data['images']:\n",
    "            img_id = img['id']\n",
    "            #print(img_id)\n",
    "            assert img_id not in imgid2path\n",
    "            anns = imgid2anns[img_id]\n",
    "            # if there is crowd gt, skip this image\n",
    "            if coco and any(ann['iscrowd'] for ann in anns):\n",
    "                continue\n",
    "\n",
    "            img_ids.append(img_id)\n",
    "            imgid2path[img_id] = os.path.join(img_dir, img['file_name'])\n",
    "            imgid2info[img['id']] = img\n",
    "\n",
    "        catids = [cat['id'] for cat in json_data['categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations /localdata/saurabh/dataset/FES/coco/annotations/instances_default_with_rbbox.json into memory...\n"
     ]
    }
   ],
   "source": [
    "coco =  False\n",
    "img_ids = []\n",
    "imgid2info = dict()\n",
    "imgid2path = dict()\n",
    "imgid2anns = defaultdict(list)\n",
    "catids = []\n",
    "\n",
    "if dataset == 'fes':\n",
    "    load_anns(\"/localdata/saurabh/dataset/FES/JPEGImages/\", \"/localdata/saurabh/dataset/FES/coco/annotations/instances_default_with_rbbox.json\" )\n",
    "elif dataset == 'custom':\n",
    "    load_anns(\"/localdata/saurabh/dataset/theodore_v3/images/\", \"/localdata/saurabh/dataset/theodore_v3/coco/annotations/instances.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run this to get image_ids in sequence starting with 1 #####\n",
    "image_ids = []\n",
    "for i in range(len(imgid2info)):\n",
    "    file_name = imgid2info[i+1]['file_name'].split('.')[0]\n",
    "    if file_name in image_names:\n",
    "        image_ids += [i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_path = [imgid2path[int(ids)] for ids in image_ids]\n",
    "annotations = [imgid2anns[int(ids)] for ids in image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Record_00893',\n",
       " 'Record_00888',\n",
       " 'Record_00855',\n",
       " 'Record_00826',\n",
       " 'Record_00880',\n",
       " 'Record_00886',\n",
       " 'Record_00805',\n",
       " 'Record_00803',\n",
       " 'Record_00809',\n",
       " 'Record_00812',\n",
       " 'Record_00890',\n",
       " 'Record_00858',\n",
       " 'Record_00804',\n",
       " 'Record_00879',\n",
       " 'Record_00857',\n",
       " 'Record_00881',\n",
       " 'Record_00872',\n",
       " 'Record_00852',\n",
       " 'Record_00848',\n",
       " 'Record_00802',\n",
       " 'Record_00824',\n",
       " 'Record_00842',\n",
       " 'Record_00868',\n",
       " 'Record_00818',\n",
       " 'Record_00806',\n",
       " 'Record_00836',\n",
       " 'Record_00819',\n",
       " 'Record_00816',\n",
       " 'Record_00827',\n",
       " 'Record_00887',\n",
       " 'Record_00839',\n",
       " 'Record_00837',\n",
       " 'Record_00845',\n",
       " 'Record_00873',\n",
       " 'Record_00835',\n",
       " 'Record_00877',\n",
       " 'Record_00821',\n",
       " 'Record_00831',\n",
       " 'Record_00882',\n",
       " 'Record_00823',\n",
       " 'Record_00899',\n",
       " 'Record_00889',\n",
       " 'Record_00892',\n",
       " 'Record_00900',\n",
       " 'Record_00830',\n",
       " 'Record_00870',\n",
       " 'Record_00894',\n",
       " 'Record_00844',\n",
       " 'Record_00807',\n",
       " 'Record_00897',\n",
       " 'Record_00878',\n",
       " 'Record_00859',\n",
       " 'Record_00856',\n",
       " 'Record_00832',\n",
       " 'Record_00815',\n",
       " 'Record_00884',\n",
       " 'Record_00874',\n",
       " 'Record_00863',\n",
       " 'Record_00850',\n",
       " 'Record_00822',\n",
       " 'Record_00829',\n",
       " 'Record_00814',\n",
       " 'Record_00885',\n",
       " 'Record_00820',\n",
       " 'Record_00851',\n",
       " 'Record_00833',\n",
       " 'Record_00817',\n",
       " 'Record_00811',\n",
       " 'Record_00838',\n",
       " 'Record_00866',\n",
       " 'Record_00876',\n",
       " 'Record_00865',\n",
       " 'Record_00896',\n",
       " 'Record_00862',\n",
       " 'Record_00800',\n",
       " 'Record_00808',\n",
       " 'Record_00861',\n",
       " 'Record_00895',\n",
       " 'Record_00860',\n",
       " 'Record_00883',\n",
       " 'Record_00810',\n",
       " 'Record_00871',\n",
       " 'Record_00840',\n",
       " 'Record_00834',\n",
       " 'Record_00864',\n",
       " 'Record_00843',\n",
       " 'Record_00813',\n",
       " 'Record_00801',\n",
       " 'Record_00867',\n",
       " 'Record_00847',\n",
       " 'Record_00869',\n",
       " 'Record_00846',\n",
       " 'Record_00849',\n",
       " 'Record_00875',\n",
       " 'Record_00898',\n",
       " 'Record_00841',\n",
       " 'Record_00853',\n",
       " 'Record_00854',\n",
       " 'Record_00891',\n",
       " 'Record_00825',\n",
       " 'Record_00828']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {1:0, 2:1, 3:2, 4:3, 5:4, 6:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record_00828\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "text_names = open(f'/localdata/saurabh/yolov3/data/{dataset}/{mode_in}_paths.txt', \"w\")\n",
    "for i, ann in enumerate(annotations):\n",
    "    file_name = image_names[i]\n",
    "    #### Append the path list\n",
    "    text_names.write(f'/localdata/saurabh/yolov3/data/{dataset}/images/{mode_in}/{file_name}.png')\n",
    "    text_names.write('\\n')\n",
    "    #### Open the label file for each anno\n",
    "    text_file = open(f'/localdata/saurabh/yolov3/data/{dataset}/labels/{mode_in}/{file_name}.txt', \"w\") \n",
    "    for anno in ann:\n",
    "        #print(anno['category_id'])\n",
    "        text_file.write(\"%i \" %label_map[anno['category_id']])\n",
    "        text_file.writelines([\"%f \" % item  for item in anno['bbox']])\n",
    "        text_file.write(\"\\n\")\n",
    "    \n",
    "    text_file.close()\n",
    "    #break\n",
    "text_names.close()\n",
    "\n",
    "print(file_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/localdata/saurabh/dataset/omnidetector-Flat_(Record_01)/coco/annotations/captions_training.json', 'r') as f:\n",
    "            json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yol",
   "language": "python",
   "name": "yol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
