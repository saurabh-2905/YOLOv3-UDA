{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.12s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7200x7200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba574b1e2b29466ca8831c5b15289544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='index', max=300), Checkbox(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import cv2\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#import colormap as cmap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def visualize(index, masks, bounding_boxes):\n",
    "    image = coco.loadImgs(coco.getImgIds()[index])[0]    \n",
    "    anno_ids = coco.getAnnIds(imgIds=[image[\"id\"]])\n",
    "    annos = coco.loadAnns(anno_ids) \n",
    "    \n",
    "    \"\"\"new_annos = []\n",
    "    for single in annos:\n",
    "        single = get_angles(single)\n",
    "        new_annos.append([single])\n",
    "    \n",
    "    annos = new_annos\"\"\"\n",
    "    filename = os.path.join(data_folder,image[\"file_name\"])\n",
    "    img = cv2.imread(str(filename))\n",
    "    print(img.shape)\n",
    "    for anno in annos:\n",
    "        #print(anno)\n",
    "        anno = get_angles(anno)\n",
    "        #c = tuple([int(x) for x in anno[\"category_id\"]])         \n",
    "        if masks:\n",
    "            points = np.array(anno[\"segmentation\"], dtype=np.int32).reshape(1,-1,2)\n",
    "            img = cv2.polylines(img, points, True, 3)\n",
    "        \n",
    "        if bounding_boxes:  \n",
    "                x,y,w,h,a = np.array(anno[\"bbox\"]).astype(np.int32)\n",
    "                #img = cv2.rectangle(img, (x,y),(x + w,y + h),(0,255,255), 3) \n",
    "                img = draw_xywha(img,x,y,w,h,a)\n",
    "                cat = coco.cats[anno['category_id']]['name']\n",
    "                cv2.putText(img, cat, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX ,  0.8, 1, cv2.LINE_AA)            \n",
    "                \n",
    "    \n",
    "    plt.imshow(img[...,::-1])\n",
    "    plt.axis(\"off\")\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def get_angles(ann):\n",
    "    \n",
    "    #print(ann['bbox'])\n",
    "    img_id = ann['image_id']\n",
    "    new_ann = None\n",
    "    # get width and height\n",
    "    if not 'rbbox' in ann:\n",
    "        # using COCO dataset. 4 = [x1,y1,w,h]\n",
    "        coco = True\n",
    "        # convert COCO format: x1,y1,w,h to x,y,w,h\n",
    "        ann['bbox'][0] = ann['bbox'][0] + ann['bbox'][2] / 2\n",
    "        ann['bbox'][1] = ann['bbox'][1] + ann['bbox'][3] / 2\n",
    "        ann['bbox'].append(0)\n",
    "        if ann['bbox'][2] > ann['bbox'][3]:\n",
    "            ann['bbox'][2],ann['bbox'][3] = ann['bbox'][3],ann['bbox'][2]\n",
    "            ann['bbox'][4] -= 90\n",
    "        new_ann = ann['bbox']\n",
    "    else:\n",
    "        # using rotated bounding box datasets. 5 = [cx,cy,w,h,angle]\n",
    "        assert len(ann['rbbox']) == 5, 'Unknown bbox format' # x,y,w,h,a\n",
    "        new_ann = ann['rbbox']\n",
    "        \n",
    "\n",
    "        if new_ann[2] > new_ann[3]:\n",
    "            new_ann[2], new_ann[3] = new_ann[3],new_ann[2]\n",
    "            new_ann[4] -= 90 if new_ann[4] > 0 else -90\n",
    "\n",
    "    if new_ann[2] == new_ann[3]:\n",
    "        new_ann[3] += 1 # force that w < h\n",
    "        \n",
    "    new_ann[4] = np.clip(new_ann[4], -90.0, 90.0 - 1e-14)\n",
    "\n",
    "    assert new_ann[2] < new_ann[3]\n",
    "    assert new_ann[4] >= -90 and new_ann[4] < 90\n",
    "\n",
    "    # override original bounding box with rotated bounding box\n",
    "    ann['bbox'] = torch.Tensor(new_ann)\n",
    "    #print(ann['bbox'])\n",
    "    return ann\n",
    "\n",
    "    \n",
    "def draw_xywha(im, x, y, w, h, angle, color=(255,0,0), linewidth=5):\n",
    "    '''\n",
    "    im: image numpy array, shape(h,w,3), RGB\n",
    "    angle: degree\n",
    "    '''\n",
    "    c, s = np.cos(angle/180*np.pi), np.sin(angle/180*np.pi)\n",
    "    R = np.asarray([[c, s], [-s, c]])\n",
    "    pts = np.asarray([[-w/2, -h/2], [w/2, -h/2], [w/2, h/2], [-w/2, h/2]])\n",
    "    rot_pts = []\n",
    "    for pt in pts:\n",
    "        rot_pts.append(([x, y] + pt @ R).astype(int))\n",
    "    contours = np.array([rot_pts[0], rot_pts[1], rot_pts[2], rot_pts[3]])\n",
    "    cv2.polylines(im, [contours], isClosed=True, color=color,\n",
    "                thickness=linewidth, lineType=cv2.LINE_4)\n",
    "    return im\n",
    "    \n",
    "    \n",
    "data_folder = \"/localdata/saurabh/dataset/FES/JPEGImages/\"\n",
    "coco = COCO(\"/localdata/saurabh/dataset/FES/coco/annotations/instances_default_with_rbbox.json\")\n",
    "#data_folder = \"/localdata/saurabh/dataset/omnidetector-Flat_(Record_01)/JPEGImages/\"\n",
    "#coco = COCO(\"/localdata/saurabh/dataset/omnidetector-Flat_(Record_01)/coco/annotations/instances_training.json\")\n",
    "plt.figure(figsize=(100,100))\n",
    "total = len(coco.getImgIds()) - 1\n",
    "\n",
    "interact(visualize, index=widgets.IntSlider(min=0, max=total, step=1, continuous_update=False), masks=False, bounding_boxes=True);  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## NOTE #######\n",
    "'''Last performed for FES dataset. The logic differes slightly for other datasets. \n",
    "Take care of image extensions and image_names variable during implementation.\n",
    "Logic of load annotation is verified. \n",
    "Do visualize the targets before training to check if correct annotations are saved'''\n",
    "####### NOTE ######\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "###Input####\n",
    "mode_in = ''\n",
    "dataset = ''\n",
    "image_paths = glob.glob(f\"/localdata/saurabh/yolov3/data/{dataset}/images/{mode_in}/*.jpg\")\n",
    "############\n",
    "\n",
    "\n",
    "image_ids = []\n",
    "image_names = []\n",
    "#print(image_paths[0])\n",
    "##### Edit this part according to the name of the files ####\n",
    "for image in image_paths:\n",
    "    #print(image)\n",
    "    image_name, image_ext = os.path.splitext(os.path.basename(image))\n",
    "    #print(image_name)\n",
    "    image_names += [image_name]\n",
    "    image_name = image_name.split('_')[1]     # Varies according to databases. Check if name is correct wrt to anno\n",
    "    image_ids += [image_name]     # If image_ids != image_names, execute the function below to get sequential image ids\n",
    "    #break\n",
    "    \n",
    "#print(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Record_00893',\n",
       " 'Record_00888',\n",
       " 'Record_00855',\n",
       " 'Record_00826',\n",
       " 'Record_00880',\n",
       " 'Record_00886',\n",
       " 'Record_00805',\n",
       " 'Record_00803',\n",
       " 'Record_00809',\n",
       " 'Record_00812',\n",
       " 'Record_00890',\n",
       " 'Record_00858',\n",
       " 'Record_00804',\n",
       " 'Record_00879',\n",
       " 'Record_00857',\n",
       " 'Record_00881',\n",
       " 'Record_00872',\n",
       " 'Record_00852',\n",
       " 'Record_00848',\n",
       " 'Record_00802',\n",
       " 'Record_00824',\n",
       " 'Record_00842',\n",
       " 'Record_00868',\n",
       " 'Record_00818',\n",
       " 'Record_00806',\n",
       " 'Record_00836',\n",
       " 'Record_00819',\n",
       " 'Record_00816',\n",
       " 'Record_00827',\n",
       " 'Record_00887',\n",
       " 'Record_00839',\n",
       " 'Record_00837',\n",
       " 'Record_00845',\n",
       " 'Record_00873',\n",
       " 'Record_00835',\n",
       " 'Record_00877',\n",
       " 'Record_00821',\n",
       " 'Record_00831',\n",
       " 'Record_00882',\n",
       " 'Record_00823',\n",
       " 'Record_00899',\n",
       " 'Record_00889',\n",
       " 'Record_00892',\n",
       " 'Record_00900',\n",
       " 'Record_00830',\n",
       " 'Record_00870',\n",
       " 'Record_00894',\n",
       " 'Record_00844',\n",
       " 'Record_00807',\n",
       " 'Record_00897',\n",
       " 'Record_00878',\n",
       " 'Record_00859',\n",
       " 'Record_00856',\n",
       " 'Record_00832',\n",
       " 'Record_00815',\n",
       " 'Record_00884',\n",
       " 'Record_00874',\n",
       " 'Record_00863',\n",
       " 'Record_00850',\n",
       " 'Record_00822',\n",
       " 'Record_00829',\n",
       " 'Record_00814',\n",
       " 'Record_00885',\n",
       " 'Record_00820',\n",
       " 'Record_00851',\n",
       " 'Record_00833',\n",
       " 'Record_00817',\n",
       " 'Record_00811',\n",
       " 'Record_00838',\n",
       " 'Record_00866',\n",
       " 'Record_00876',\n",
       " 'Record_00865',\n",
       " 'Record_00896',\n",
       " 'Record_00862',\n",
       " 'Record_00800',\n",
       " 'Record_00808',\n",
       " 'Record_00861',\n",
       " 'Record_00895',\n",
       " 'Record_00860',\n",
       " 'Record_00883',\n",
       " 'Record_00810',\n",
       " 'Record_00871',\n",
       " 'Record_00840',\n",
       " 'Record_00834',\n",
       " 'Record_00864',\n",
       " 'Record_00843',\n",
       " 'Record_00813',\n",
       " 'Record_00801',\n",
       " 'Record_00867',\n",
       " 'Record_00847',\n",
       " 'Record_00869',\n",
       " 'Record_00846',\n",
       " 'Record_00849',\n",
       " 'Record_00875',\n",
       " 'Record_00898',\n",
       " 'Record_00841',\n",
       " 'Record_00853',\n",
       " 'Record_00854',\n",
       " 'Record_00891',\n",
       " 'Record_00825',\n",
       " 'Record_00828']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Process and load annotatinos according to RAPID implementation\n",
    "def load_anns(img_dir,json_path):\n",
    "        coco = False\n",
    "        print(f'Loading annotations {json_path} into memory...')\n",
    "        with open(json_path, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        for ann in json_data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            #print(img_id)\n",
    "            new_ann = None\n",
    "            # get width and height \n",
    "            if not 'rbbox' in ann:\n",
    "                # using COCO dataset. 4 = [x1,y1,w,h]\n",
    "                coco = True\n",
    "                ann['bbox'][0] = ann['bbox'][0] + ann['bbox'][2] / 2\n",
    "                ann['bbox'][1] = ann['bbox'][1] + ann['bbox'][3] / 2\n",
    "                ann['bbox'].append(0)\n",
    "                if ann['bbox'][2] > ann['bbox'][3]:\n",
    "                    ann['bbox'][2],ann['bbox'][3] = ann['bbox'][3],ann['bbox'][2]\n",
    "                    ann['bbox'][4] -= 90\n",
    "                new_ann = ann['bbox']\n",
    "            else:\n",
    "                # using rotated bounding box datasets. 5 = [cx,cy,w,h,angle]\n",
    "                assert len(ann['rbbox']) == 5, 'Unknown bbox format' # x,y,w,h,a\n",
    "                new_ann = ann['rbbox']\n",
    "\n",
    "\n",
    "                if new_ann[2] > new_ann[3]:\n",
    "                    new_ann[2], new_ann[3] = new_ann[3],new_ann[2]\n",
    "                    new_ann[4] -= 90 if new_ann[4] > 0 else -90\n",
    "\n",
    "            if new_ann[2] == new_ann[3]:\n",
    "                new_ann[3] += 1 # force that w < h\n",
    "\n",
    "            new_ann[4] = np.clip(new_ann[4], -90.0, 90.0 - 1e-14)\n",
    "\n",
    "            assert new_ann[2] < new_ann[3]\n",
    "            assert new_ann[4] >= -90 and new_ann[4] < 90\n",
    "\n",
    "            # override original bounding box with rotated bounding box\n",
    "            ann['bbox'] = torch.Tensor(new_ann)\n",
    "            #print(img_id)\n",
    "            imgid2anns[img_id].append(ann)\n",
    "\n",
    "        for img in json_data['images']:\n",
    "            img_id = img['id']\n",
    "            #print(img_id)\n",
    "            assert img_id not in imgid2path\n",
    "            anns = imgid2anns[img_id]\n",
    "            # if there is crowd gt, skip this image\n",
    "            if coco and any(ann['iscrowd'] for ann in anns):\n",
    "                continue\n",
    "\n",
    "            img_ids.append(img_id)\n",
    "            imgid2path[img_id] = os.path.join(img_dir, img['file_name'])\n",
    "            imgid2info[img['id']] = img\n",
    "\n",
    "        catids = [cat['id'] for cat in json_data['categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations /localdata/saurabh/dataset/FES/coco/annotations/instances_default_with_rbbox.json into memory...\n"
     ]
    }
   ],
   "source": [
    "### Store the required values generated during load_anns function\n",
    "coco =  False\n",
    "img_ids = []\n",
    "imgid2info = dict()\n",
    "imgid2path = dict()\n",
    "imgid2anns = defaultdict(list)\n",
    "catids = []\n",
    "\n",
    "if dataset == 'fes':\n",
    "    load_anns(\"/localdata/saurabh/dataset/FES/JPEGImages/\", \"/localdata/saurabh/dataset/FES/coco/annotations/instances_default_with_rbbox.json\" )\n",
    "elif dataset == 'custom':\n",
    "    load_anns(\"/localdata/saurabh/dataset/theodore_v3/images/\", \"/localdata/saurabh/dataset/theodore_v3/coco/annotations/instances.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 105,\n",
       " 'width': 1680,\n",
       " 'height': 1680,\n",
       " 'file_name': 'Record_00704.jpg',\n",
       " 'license': 0,\n",
       " 'flickr_url': '',\n",
       " 'coco_url': '',\n",
       " 'date_captured': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgid2info[105] # just to cross check the image_id-image_name pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record_00600 1\n",
      "Record_00601 2\n",
      "Record_00602 3\n",
      "Record_00603 4\n",
      "Record_00604 5\n",
      "Record_00605 6\n",
      "Record_00606 7\n",
      "Record_00607 8\n",
      "Record_00608 9\n",
      "Record_00609 10\n",
      "Record_00610 11\n",
      "Record_00611 12\n",
      "Record_00612 13\n",
      "Record_00613 14\n",
      "Record_00614 15\n",
      "Record_00615 16\n",
      "Record_00616 17\n",
      "Record_00617 18\n",
      "Record_00618 19\n",
      "Record_00619 20\n",
      "Record_00620 21\n",
      "Record_00621 22\n",
      "Record_00622 23\n",
      "Record_00623 24\n",
      "Record_00624 25\n",
      "Record_00625 26\n",
      "Record_00626 27\n",
      "Record_00627 28\n",
      "Record_00628 29\n",
      "Record_00629 30\n",
      "Record_00630 31\n",
      "Record_00631 32\n",
      "Record_00632 33\n",
      "Record_00633 34\n",
      "Record_00634 35\n",
      "Record_00635 36\n",
      "Record_00636 37\n",
      "Record_00637 38\n",
      "Record_00638 39\n",
      "Record_00639 40\n",
      "Record_00640 41\n",
      "Record_00641 42\n",
      "Record_00642 43\n",
      "Record_00643 44\n",
      "Record_00644 45\n",
      "Record_00645 46\n",
      "Record_00646 47\n",
      "Record_00647 48\n",
      "Record_00648 49\n",
      "Record_00649 50\n",
      "Record_00650 51\n",
      "Record_00651 52\n",
      "Record_00652 53\n",
      "Record_00653 54\n",
      "Record_00654 55\n",
      "Record_00655 56\n",
      "Record_00656 57\n",
      "Record_00657 58\n",
      "Record_00658 59\n",
      "Record_00659 60\n",
      "Record_00660 61\n",
      "Record_00661 62\n",
      "Record_00662 63\n",
      "Record_00663 64\n",
      "Record_00664 65\n",
      "Record_00665 66\n",
      "Record_00666 67\n",
      "Record_00667 68\n",
      "Record_00668 69\n",
      "Record_00669 70\n",
      "Record_00670 71\n",
      "Record_00671 72\n",
      "Record_00672 73\n",
      "Record_00673 74\n",
      "Record_00674 75\n",
      "Record_00675 76\n",
      "Record_00676 77\n",
      "Record_00677 78\n",
      "Record_00678 79\n",
      "Record_00679 80\n",
      "Record_00680 81\n",
      "Record_00681 82\n",
      "Record_00682 83\n",
      "Record_00683 84\n",
      "Record_00684 85\n",
      "Record_00685 86\n",
      "Record_00686 87\n",
      "Record_00687 88\n",
      "Record_00688 89\n",
      "Record_00689 90\n",
      "Record_00690 91\n",
      "Record_00691 92\n",
      "Record_00692 93\n",
      "Record_00693 94\n",
      "Record_00694 95\n",
      "Record_00695 96\n",
      "Record_00696 97\n",
      "Record_00697 98\n",
      "Record_00698 99\n",
      "Record_00699 100\n",
      "Record_00700 101\n",
      "Record_00701 102\n",
      "Record_00702 103\n",
      "Record_00703 104\n",
      "Record_00704 105\n",
      "Record_00705 106\n",
      "Record_00706 107\n",
      "Record_00707 108\n",
      "Record_00708 109\n",
      "Record_00709 110\n",
      "Record_00710 111\n",
      "Record_00711 112\n",
      "Record_00712 113\n",
      "Record_00713 114\n",
      "Record_00714 115\n",
      "Record_00715 116\n",
      "Record_00716 117\n",
      "Record_00717 118\n",
      "Record_00718 119\n",
      "Record_00719 120\n",
      "Record_00720 121\n",
      "Record_00721 122\n",
      "Record_00722 123\n",
      "Record_00723 124\n",
      "Record_00724 125\n",
      "Record_00725 126\n",
      "Record_00726 127\n",
      "Record_00727 128\n",
      "Record_00728 129\n",
      "Record_00729 130\n",
      "Record_00730 131\n",
      "Record_00731 132\n",
      "Record_00732 133\n",
      "Record_00733 134\n",
      "Record_00734 135\n",
      "Record_00735 136\n",
      "Record_00736 137\n",
      "Record_00737 138\n",
      "Record_00738 139\n",
      "Record_00739 140\n",
      "Record_00740 141\n",
      "Record_00741 142\n",
      "Record_00742 143\n",
      "Record_00743 144\n",
      "Record_00744 145\n",
      "Record_00745 146\n",
      "Record_00746 147\n",
      "Record_00747 148\n",
      "Record_00748 149\n",
      "Record_00749 150\n",
      "Record_00750 151\n",
      "Record_00751 152\n",
      "Record_00752 153\n",
      "Record_00753 154\n",
      "Record_00754 155\n",
      "Record_00755 156\n",
      "Record_00756 157\n",
      "Record_00757 158\n",
      "Record_00758 159\n",
      "Record_00759 160\n",
      "Record_00760 161\n",
      "Record_00761 162\n",
      "Record_00762 163\n",
      "Record_00763 164\n",
      "Record_00764 165\n",
      "Record_00765 166\n",
      "Record_00766 167\n",
      "Record_00767 168\n",
      "Record_00768 169\n",
      "Record_00769 170\n",
      "Record_00770 171\n",
      "Record_00771 172\n",
      "Record_00772 173\n",
      "Record_00773 174\n",
      "Record_00774 175\n",
      "Record_00775 176\n",
      "Record_00776 177\n",
      "Record_00777 178\n",
      "Record_00778 179\n",
      "Record_00779 180\n",
      "Record_00780 181\n",
      "Record_00781 182\n",
      "Record_00782 183\n",
      "Record_00783 184\n",
      "Record_00784 185\n",
      "Record_00785 186\n",
      "Record_00786 187\n",
      "Record_00787 188\n",
      "Record_00788 189\n",
      "Record_00789 190\n",
      "Record_00790 191\n",
      "Record_00791 192\n",
      "Record_00792 193\n",
      "Record_00793 194\n",
      "Record_00794 195\n",
      "Record_00795 196\n",
      "Record_00796 197\n",
      "Record_00797 198\n",
      "Record_00798 199\n",
      "Record_00799 200\n"
     ]
    }
   ],
   "source": [
    "#### Run this to get image_ids in sequence starting with 1 #####\n",
    "'''Do not run if image_id=image_name'''\n",
    "\n",
    "image_ids = []\n",
    "for i in range(len(imgid2info)):\n",
    "    file_name = imgid2info[i+1]['file_name'].split('.')[0]\n",
    "    #i_d = imgid2info\n",
    "    \n",
    "    if file_name in image_names:  # Make sure names in both list are identical\n",
    "        image_ids += [i+1]\n",
    "        print(file_name, i+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_names = sorted(image_names) #if image_ids are sequential then sort the names accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Record_00600',\n",
       " 'Record_00601',\n",
       " 'Record_00602',\n",
       " 'Record_00603',\n",
       " 'Record_00604',\n",
       " 'Record_00605',\n",
       " 'Record_00606',\n",
       " 'Record_00607',\n",
       " 'Record_00608',\n",
       " 'Record_00609',\n",
       " 'Record_00610',\n",
       " 'Record_00611',\n",
       " 'Record_00612',\n",
       " 'Record_00613',\n",
       " 'Record_00614',\n",
       " 'Record_00615',\n",
       " 'Record_00616',\n",
       " 'Record_00617',\n",
       " 'Record_00618',\n",
       " 'Record_00619',\n",
       " 'Record_00620',\n",
       " 'Record_00621',\n",
       " 'Record_00622',\n",
       " 'Record_00623',\n",
       " 'Record_00624',\n",
       " 'Record_00625',\n",
       " 'Record_00626',\n",
       " 'Record_00627',\n",
       " 'Record_00628',\n",
       " 'Record_00629',\n",
       " 'Record_00630',\n",
       " 'Record_00631',\n",
       " 'Record_00632',\n",
       " 'Record_00633',\n",
       " 'Record_00634',\n",
       " 'Record_00635',\n",
       " 'Record_00636',\n",
       " 'Record_00637',\n",
       " 'Record_00638',\n",
       " 'Record_00639',\n",
       " 'Record_00640',\n",
       " 'Record_00641',\n",
       " 'Record_00642',\n",
       " 'Record_00643',\n",
       " 'Record_00644',\n",
       " 'Record_00645',\n",
       " 'Record_00646',\n",
       " 'Record_00647',\n",
       " 'Record_00648',\n",
       " 'Record_00649',\n",
       " 'Record_00650',\n",
       " 'Record_00651',\n",
       " 'Record_00652',\n",
       " 'Record_00653',\n",
       " 'Record_00654',\n",
       " 'Record_00655',\n",
       " 'Record_00656',\n",
       " 'Record_00657',\n",
       " 'Record_00658',\n",
       " 'Record_00659',\n",
       " 'Record_00660',\n",
       " 'Record_00661',\n",
       " 'Record_00662',\n",
       " 'Record_00663',\n",
       " 'Record_00664',\n",
       " 'Record_00665',\n",
       " 'Record_00666',\n",
       " 'Record_00667',\n",
       " 'Record_00668',\n",
       " 'Record_00669',\n",
       " 'Record_00670',\n",
       " 'Record_00671',\n",
       " 'Record_00672',\n",
       " 'Record_00673',\n",
       " 'Record_00674',\n",
       " 'Record_00675',\n",
       " 'Record_00676',\n",
       " 'Record_00677',\n",
       " 'Record_00678',\n",
       " 'Record_00679',\n",
       " 'Record_00680',\n",
       " 'Record_00681',\n",
       " 'Record_00682',\n",
       " 'Record_00683',\n",
       " 'Record_00684',\n",
       " 'Record_00685',\n",
       " 'Record_00686',\n",
       " 'Record_00687',\n",
       " 'Record_00688',\n",
       " 'Record_00689',\n",
       " 'Record_00690',\n",
       " 'Record_00691',\n",
       " 'Record_00692',\n",
       " 'Record_00693',\n",
       " 'Record_00694',\n",
       " 'Record_00695',\n",
       " 'Record_00696',\n",
       " 'Record_00697',\n",
       " 'Record_00698',\n",
       " 'Record_00699',\n",
       " 'Record_00700',\n",
       " 'Record_00701',\n",
       " 'Record_00702',\n",
       " 'Record_00703',\n",
       " 'Record_00704',\n",
       " 'Record_00705',\n",
       " 'Record_00706',\n",
       " 'Record_00707',\n",
       " 'Record_00708',\n",
       " 'Record_00709',\n",
       " 'Record_00710',\n",
       " 'Record_00711',\n",
       " 'Record_00712',\n",
       " 'Record_00713',\n",
       " 'Record_00714',\n",
       " 'Record_00715',\n",
       " 'Record_00716',\n",
       " 'Record_00717',\n",
       " 'Record_00718',\n",
       " 'Record_00719',\n",
       " 'Record_00720',\n",
       " 'Record_00721',\n",
       " 'Record_00722',\n",
       " 'Record_00723',\n",
       " 'Record_00724',\n",
       " 'Record_00725',\n",
       " 'Record_00726',\n",
       " 'Record_00727',\n",
       " 'Record_00728',\n",
       " 'Record_00729',\n",
       " 'Record_00730',\n",
       " 'Record_00731',\n",
       " 'Record_00732',\n",
       " 'Record_00733',\n",
       " 'Record_00734',\n",
       " 'Record_00735',\n",
       " 'Record_00736',\n",
       " 'Record_00737',\n",
       " 'Record_00738',\n",
       " 'Record_00739',\n",
       " 'Record_00740',\n",
       " 'Record_00741',\n",
       " 'Record_00742',\n",
       " 'Record_00743',\n",
       " 'Record_00744',\n",
       " 'Record_00745',\n",
       " 'Record_00746',\n",
       " 'Record_00747',\n",
       " 'Record_00748',\n",
       " 'Record_00749',\n",
       " 'Record_00750',\n",
       " 'Record_00751',\n",
       " 'Record_00752',\n",
       " 'Record_00753',\n",
       " 'Record_00754',\n",
       " 'Record_00755',\n",
       " 'Record_00756',\n",
       " 'Record_00757',\n",
       " 'Record_00758',\n",
       " 'Record_00759',\n",
       " 'Record_00760',\n",
       " 'Record_00761',\n",
       " 'Record_00762',\n",
       " 'Record_00763',\n",
       " 'Record_00764',\n",
       " 'Record_00765',\n",
       " 'Record_00766',\n",
       " 'Record_00767',\n",
       " 'Record_00768',\n",
       " 'Record_00769',\n",
       " 'Record_00770',\n",
       " 'Record_00771',\n",
       " 'Record_00772',\n",
       " 'Record_00773',\n",
       " 'Record_00774',\n",
       " 'Record_00775',\n",
       " 'Record_00776',\n",
       " 'Record_00777',\n",
       " 'Record_00778',\n",
       " 'Record_00779',\n",
       " 'Record_00780',\n",
       " 'Record_00781',\n",
       " 'Record_00782',\n",
       " 'Record_00783',\n",
       " 'Record_00784',\n",
       " 'Record_00785',\n",
       " 'Record_00786',\n",
       " 'Record_00787',\n",
       " 'Record_00788',\n",
       " 'Record_00789',\n",
       " 'Record_00790',\n",
       " 'Record_00791',\n",
       " 'Record_00792',\n",
       " 'Record_00793',\n",
       " 'Record_00794',\n",
       " 'Record_00795',\n",
       " 'Record_00796',\n",
       " 'Record_00797',\n",
       " 'Record_00798',\n",
       " 'Record_00799']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get annotations only for the train/val set according to image_ids\n",
    "ind_path = [imgid2path[int(ids)] for ids in image_ids]\n",
    "annotations = [imgid2anns[int(ids)] for ids in image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Map the labels to 0-indexed labels\n",
    "label_map = {1:0, 2:1, 3:2, 4:3, 5:4, 6:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record_00799\n"
     ]
    }
   ],
   "source": [
    "##### Save the paths to the images and annotations as .txt files\n",
    "\n",
    "all_images = []\n",
    "text_names = open(f'/localdata/saurabh/yolov3/data/{dataset}/{mode_in}_paths.txt', \"w\")\n",
    "for i, ann in enumerate(annotations):\n",
    "    file_name = image_names[i]     # image_names should be in sync with annotation sequence\n",
    "    #### Append the path list\n",
    "    text_names.write(f'/localdata/saurabh/yolov3/data/{dataset}/images/{mode_in}/{file_name}{image_ext}')\n",
    "    text_names.write('\\n')\n",
    "    #### Open the label file for each anno\n",
    "    text_file = open(f'/localdata/saurabh/yolov3/data/{dataset}/labels/{mode_in}/{file_name}.txt', \"w\") \n",
    "    for anno in ann:\n",
    "        #print(anno['category_id'])\n",
    "        text_file.write(\"%i \" %label_map[anno['category_id']])\n",
    "        text_file.writelines([\"%f \" % item  for item in anno['bbox']])\n",
    "        text_file.write(\"\\n\")\n",
    "    \n",
    "    text_file.close()\n",
    "    #break\n",
    "text_names.close()\n",
    "\n",
    "print(file_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/localdata/saurabh/dataset/omnidetector-Flat_(Record_01)/coco/annotations/captions_training.json', 'r') as f:\n",
    "            json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yol",
   "language": "python",
   "name": "yol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
